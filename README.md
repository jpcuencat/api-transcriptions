# ğŸ¥ API Transcriptions

Una API robusta desarrollada en **FastAPI** para transcripciÃ³n automÃ¡tica de videos, traducciÃ³n de contenido y generaciÃ³n de subtÃ­tulos usando **Whisper** de OpenAI y modelos de traducciÃ³n **Helsinki-NLP**.

## âœ¨ CaracterÃ­sticas Principales

- ğŸ¯ **TranscripciÃ³n automÃ¡tica** de videos usando Whisper (OpenAI)
- ğŸŒ **TraducciÃ³n multiidioma** con modelos locales Helsinki-NLP
- ğŸ“ **GeneraciÃ³n de subtÃ­tulos SRT** con tiempos precisos de Whisper
- ğŸ“Š **EvaluaciÃ³n de calidad** automÃ¡tica de transcripciones
- ğŸ”„ **Procesamiento asÃ­ncrono** de trabajos en background
- ğŸ›¡ï¸ **AutenticaciÃ³n por API Key** y rate limiting
- ğŸ“ **Soporte mÃºltiples formatos** de video (.mp4, .avi, .mov, .mkv, .webm)

## ğŸš€ InstalaciÃ³n RÃ¡pida

### Prerrequisitos
- Python 3.8+
- FFmpeg instalado en el sistema

### 1. Clonar el repositorio
```bash
git clone https://github.com/jpcuencat/api-transcriptions.git
cd api-transcriptions
```

### 2. Crear entorno virtual
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 4. Ejecutar la aplicaciÃ³n
```bash
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

La API estarÃ¡ disponible en: `http://localhost:8000`

## ğŸ“– DocumentaciÃ³n de la API

### Endpoints Principales

#### ğŸ¬ Transcribir Video
```http
POST /api/v1/transcribe
```

**ParÃ¡metros:**
- `video_file`: Archivo de video (form-data)
- `language`: CÃ³digo de idioma o 'auto' (opcional, default: 'auto')
- `model_size`: TamaÃ±o del modelo Whisper (opcional, default: 'base')
- `translate_to`: Idioma destino para traducciÃ³n (opcional)
- `quality_evaluation`: Habilitar evaluaciÃ³n de calidad (opcional, default: true)

**Headers:**
```
X-API-Key: dev_api_key_12345
Content-Type: multipart/form-data
```

**Respuesta:**
```json
{
  "job_id": "uuid-string",
  "status": "processing",
  "created_at": "2025-07-13T17:00:00"
}
```

#### ğŸ“Š Estado del Trabajo
```http
GET /api/v1/transcribe/{job_id}/status
```

**Respuesta exitosa:**
```json
{
  "job_id": "uuid-string",
  "status": "completed",
  "transcription_text": "Texto transcrito...",
  "translation_text": "Texto traducido...",
  "detected_language": "en",
  "segments_count": 25,
  "translation_segments_count": 25,
  "srt_available": true,
  "quality_score": 0.95,
  "processing_time": 45.6
}
```

#### â¬‡ï¸ Descargar SubtÃ­tulos
```http
GET /api/v1/transcribe/{job_id}/download
```

#### ğŸŒ Idiomas Soportados
```http
GET /api/v1/languages
```

**Respuesta:**
```json
{
  "transcription_languages": {
    "auto": "Auto-detect",
    "en": "English",
    "es": "Spanish",
    "fr": "French",
    "de": "German",
    "it": "Italian",
    "pt": "Portuguese",
    "ru": "Russian"
  },
  "translation_languages": {
    "en": "English",
    "es": "Spanish",
    "fr": "French",
    "de": "German",
    "it": "Italian",
    "pt": "Portuguese",
    "ru": "Russian"
  },
  "available_translation_pairs": {
    "en": ["es", "fr", "de", "it", "pt", "ru"],
    "es": ["en", "pt", "fr", "de", "it"],
    "fr": ["en", "es", "de", "pt"],
    "de": ["en", "es", "fr", "pt"],
    "it": ["en", "es", "pt"],
    "pt": ["en", "es", "fr", "de", "it"],
    "ru": ["en"]
  }
}
```

## ğŸ—ï¸ Arquitectura del Proyecto

```
api-transcriptions/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # Punto de entrada de la aplicaciÃ³n
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ endpoints/
â”‚   â”‚       â”œâ”€â”€ health.py       # Endpoint de salud
â”‚   â”‚       â””â”€â”€ transcription.py # Endpoints principales
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py          # ConfiguraciÃ³n global
â”‚   â”‚   â””â”€â”€ security.py        # AutenticaciÃ³n y seguridad
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py         # Modelos Pydantic
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ transcription_service.py    # Servicio principal Whisper
â”‚   â”‚   â”œâ”€â”€ subtitle_generator.py       # GeneraciÃ³n de SRT
â”‚   â”‚   â”œâ”€â”€ audio_extractor.py         # ExtracciÃ³n de audio
â”‚   â”‚   â”œâ”€â”€ quality_evaluator.py       # EvaluaciÃ³n de calidad
â”‚   â”‚   â””â”€â”€ translation_service.py     # Servicios de traducciÃ³n
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ file_handler.py     # Manejo de archivos
â”‚       â””â”€â”€ validators.py       # Validaciones
â”œâ”€â”€ temp/                       # Archivos temporales
â”‚   â”œâ”€â”€ uploads/               # Videos subidos
â”‚   â”œâ”€â”€ audio/                 # Audio extraÃ­do
â”‚   â”œâ”€â”€ srt/                   # SubtÃ­tulos generados
â”‚   â””â”€â”€ whisper_cache/         # Cache de modelos Whisper
â”œâ”€â”€ tests/                     # Pruebas unitarias
â”œâ”€â”€ requirements.txt           # Dependencias Python
â””â”€â”€ README.md                 # Este archivo
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Core Framework
- **FastAPI** - Framework web moderno y rÃ¡pido
- **Uvicorn** - Servidor ASGI de alto rendimiento
- **Pydantic** - ValidaciÃ³n de datos y serializaciÃ³n

### Procesamiento de Audio/Video
- **OpenAI Whisper** - Reconocimiento de voz de Ãºltima generaciÃ³n
- **FFmpeg-python** - ManipulaciÃ³n de archivos multimedia
- **PyTorch** - Framework de deep learning

### TraducciÃ³n
- **Helsinki-NLP/opus-mt** - Modelos de traducciÃ³n neuronal
- **Transformers (Hugging Face)** - Biblioteca de modelos pre-entrenados
- **MarianMT** - Modelos de traducciÃ³n automÃ¡tica

### Utilidades
- **aiofiles** - Operaciones de archivos asÃ­ncronas
- **python-magic** - DetecciÃ³n de tipos MIME
- **jiwer** - EvaluaciÃ³n de calidad (WER)
- **langdetect** - DetecciÃ³n automÃ¡tica de idiomas

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno
Crea un archivo `.env` en la raÃ­z del proyecto:

```env
# API Configuration
API_KEY=tu_api_key_aqui
DEBUG=True
HOST=0.0.0.0
PORT=8000

# File Processing
MAX_FILE_SIZE_MB=500
TEMP_DIR=./temp
CLEANUP_TEMP_FILES=True

# Whisper Configuration
WHISPER_MODEL_SIZE=base
WHISPER_DEVICE=auto

# Security
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600

# Logging
LOG_LEVEL=INFO
LOG_FILE=transcription_api.log
```

### Modelos Whisper Disponibles
- `tiny` - MÃ¡s rÃ¡pido, menor precisiÃ³n
- `base` - Balance entre velocidad y precisiÃ³n (recomendado)
- `small` - Buena precisiÃ³n, velocidad moderada
- `medium` - Alta precisiÃ³n, mÃ¡s lento
- `large` - MÃ¡xima precisiÃ³n, mÃ¡s lento

## ğŸ§ª Testing

```bash
# Ejecutar todas las pruebas
pytest

# Ejecutar con cobertura
pytest --cov=app

# Ejecutar pruebas especÃ­ficas
pytest tests/test_transcription.py
```

## ğŸ“ Ejemplos de Uso

### Ejemplo con cURL
```bash
# Transcribir video en inglÃ©s y traducir a espaÃ±ol
curl -X POST "http://localhost:8000/api/v1/transcribe" \
  -H "X-API-Key: dev_api_key_12345" \
  -F "video_file=@video.mp4" \
  -F "language=auto" \
  -F "translate_to=es" \
  -F "model_size=base"
```

### Ejemplo con Python
```python
import requests

# Subir video para transcripciÃ³n
response = requests.post(
    "http://localhost:8000/api/v1/transcribe",
    headers={"X-API-Key": "dev_api_key_12345"},
    files={"video_file": open("video.mp4", "rb")},
    data={
        "language": "auto",
        "translate_to": "pt",
        "model_size": "base"
    }
)

job_id = response.json()["job_id"]

# Verificar estado
status_response = requests.get(
    f"http://localhost:8000/api/v1/transcribe/{job_id}/status",
    headers={"X-API-Key": "dev_api_key_12345"}
)

# Descargar subtÃ­tulos cuando estÃ© completado
if status_response.json()["status"] == "completed":
    srt_response = requests.get(
        f"http://localhost:8000/api/v1/transcribe/{job_id}/download",
        headers={"X-API-Key": "dev_api_key_12345"}
    )
    
    with open("subtitles.srt", "wb") as f:
        f.write(srt_response.content)
```

## ğŸ”§ SoluciÃ³n de Problemas

### Errores Comunes

#### "FFmpeg not found"
```bash
# Ubuntu/Debian
sudo apt update && sudo apt install ffmpeg

# macOS
brew install ffmpeg

# Windows
# Descargar desde https://ffmpeg.org/download.html
```

#### "Model download failed"
- Verificar conexiÃ³n a internet
- Los modelos se descargan automÃ¡ticamente en el primer uso
- Espacio en disco suficiente (modelos grandes pueden ser >1GB)

#### "Translation not working"
- Verificar que el par de idiomas estÃ© soportado en `/api/v1/languages`
- Los modelos de traducciÃ³n se descargan automÃ¡ticamente cuando se usan por primera vez

## ğŸ“Š Rendimiento

### Tiempos Estimados (video de 1 minuto)
- **tiny**: ~10-15 segundos
- **base**: ~15-25 segundos  
- **small**: ~25-40 segundos
- **medium**: ~40-60 segundos
- **large**: ~60-120 segundos

*Los tiempos varÃ­an segÃºn el hardware (CPU/GPU) y la complejidad del audio*

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crear una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- [OpenAI Whisper](https://github.com/openai/whisper) - Reconocimiento de voz
- [Helsinki-NLP](https://huggingface.co/Helsinki-NLP) - Modelos de traducciÃ³n
- [FastAPI](https://fastapi.tiangolo.com/) - Framework web
- [Hugging Face](https://huggingface.co/) - Biblioteca de transformers

## ğŸ“ Soporte

Si tienes preguntas o problemas:
- Abrir un [Issue](https://github.com/jpcuencat/api-transcriptions/issues)
- Revisar la documentaciÃ³n en `/docs` (Swagger UI)
- Verificar logs en `transcription_api.log`

---

â­ Si este proyecto te fue Ãºtil, Â¡dale una estrella en GitHub!

import asyncio
import base64
import logging
import os
import tempfile
import time
import uuid
from collections import deque
from datetime import datetime
from threading import Lock
from typing import Dict, Optional

import numpy as np
import whisper

from app.models.schemas import RealTimeSession, RealTimeTranscriptionResponse
from app.services.translation_service import TranslationService


class RealTimeTranscriptionServiceV2:
    """Servicio mejorado para transcripci√≥n en tiempo real de audio de micr√≥fono"""
    
    def __init__(self):
        self.active_sessions: Dict[str, RealTimeSession] = {}
        self.audio_buffers: Dict[str, deque] = {}
        self.whisper_models: Dict[str, whisper.Whisper] = {}
        self.translation_service = TranslationService()
        self.lock = Lock()
        
        # Configuraci√≥n optimizada para tiempo real
        self.min_audio_duration = 0.1  # M√≠nima duraci√≥n de audio
        self.max_audio_duration = 30.0  # M√°xima duraci√≥n de audio
        
        logging.info("üé§ RealTimeTranscriptionServiceV2 initialized")
    
    def _load_model(self, model_size: str = "tiny") -> whisper.Whisper:
        """Carga y cachea modelos Whisper"""
        if model_size not in self.whisper_models:
            logging.info(f"ü§ñ Loading Whisper model: {model_size}")
            self.whisper_models[model_size] = whisper.load_model(model_size)
            logging.info(f"‚úÖ Whisper model {model_size} loaded successfully")
        
        return self.whisper_models[model_size]
    
    def _save_webm_file(self, audio_base64: str, session_id: str) -> str:
        """Guarda audio base64 como archivo WebM temporal"""
        temp_dir = tempfile.gettempdir()
        timestamp = int(time.time() * 1000)
        temp_path = os.path.join(temp_dir, f"realtime_{session_id}_{timestamp}.webm")
        
        try:
            audio_bytes = base64.b64decode(audio_base64)
            with open(temp_path, 'wb') as f:
                f.write(audio_bytes)
            
            file_size = os.path.getsize(temp_path)
            logging.info(f"üíæ Saved WebM: {temp_path} ({file_size} bytes)")
            return temp_path
            
        except Exception as e:
            logging.error(f"‚ùå Error saving WebM file: {e}")
            raise ValueError(f"Cannot save audio file: {e}")
    
    async def create_session(
        self, 
        session_id: str,
        language: str = "auto",
        model_size: str = "tiny",
        translate_to: Optional[str] = None
    ) -> RealTimeSession:
        """Crea una nueva sesi√≥n de transcripci√≥n en tiempo real"""
        
        session = RealTimeSession(
            session_id=session_id,
            status="active",
            language=language,
            model_size=model_size,
            translate_to=translate_to,
            created_at=datetime.now(),
            last_activity=datetime.now()
        )
        
        with self.lock:
            self.active_sessions[session_id] = session
            self.audio_buffers[session_id] = deque(maxlen=10)
        
        # Precargar modelo
        self._load_model(model_size)
        
        logging.info(f"‚úÖ Created session: {session_id} (language: {language}, model: {model_size})")
        return session
    
    async def process_audio_chunk(
        self,
        session_id: str,
        chunk_id: str,
        audio_base64: str
    ) -> Optional[RealTimeTranscriptionResponse]:
        """Procesa un chunk de audio en tiempo real con enfoque simplificado"""
        
        if session_id not in self.active_sessions:
            raise ValueError(f"Session {session_id} not found")
        
        session = self.active_sessions[session_id]
        start_time = time.time()
        
        logging.info(f"üéµ Processing chunk {chunk_id} for session {session_id}")
        
        try:
            # Validar datos de audio
            if not audio_base64:
                logging.warning(f"‚ö†Ô∏è Empty audio data for chunk {chunk_id}")
                return None
            
            # Guardar archivo temporal
            temp_audio_path = self._save_webm_file(audio_base64, session_id)
            
            try:
                # Verificar archivo
                if not os.path.exists(temp_audio_path):
                    logging.error(f"‚ùå Temp file not found: {temp_audio_path}")
                    return None
                    
                file_size = os.path.getsize(temp_audio_path)
                if file_size == 0:
                    logging.warning(f"‚ö†Ô∏è Empty file: {temp_audio_path}")
                    return None
                
                logging.info(f"üìÅ Processing file: {temp_audio_path} ({file_size} bytes)")
                
                # Transcribir con Whisper
                model = self._load_model(session.model_size)
                
                # Configuraci√≥n optimizada para tiempo real
                whisper_options = {
                    "language": None if session.language == "auto" else session.language,
                    "task": "transcribe",
                    "fp16": False,
                    "verbose": True,
                    "word_timestamps": False,
                    "condition_on_previous_text": False,
                    "no_speech_threshold": 0.4,  # M√°s permisivo
                    "logprob_threshold": -0.8,   # M√°s permisivo
                    "temperature": 0.0           # Determin√≠stico
                }
                
                logging.info(f"ü§ñ Starting Whisper transcription with options: {whisper_options}")
                result = model.transcribe(temp_audio_path, **whisper_options)
                
                # Extraer resultados
                transcription = result.get("text", "").strip()
                detected_language = result.get("language", session.language)
                segments = result.get("segments", [])
                
                logging.info(f"üìù Whisper results:")
                logging.info(f"   - Text: '{transcription}'")
                logging.info(f"   - Language: {detected_language}")
                logging.info(f"   - Segments: {len(segments)}")
                
                # Si no hay texto principal, intentar extraer de segmentos
                if not transcription and segments:
                    segment_texts = []
                    for segment in segments:
                        text = segment.get("text", "").strip()
                        if text:
                            segment_texts.append(text)
                            logging.info(f"   - Segment text: '{text}'")
                    
                    if segment_texts:
                        transcription = " ".join(segment_texts)
                        logging.info(f"üìù Extracted from segments: '{transcription}'")
                
                # Calcular duraci√≥n estimada
                duration = 2.0  # Duraci√≥n estimada de chunk
                
                # Traducir si es necesario
                translation = None
                if session.translate_to and transcription:
                    logging.info(f"üåç Translating to {session.translate_to}")
                    try:
                        translation = await self.translation_service.translate_text(
                            transcription,
                            source_language=detected_language,
                            target_language=session.translate_to
                        )
                        logging.info(f"üåç Translation: '{translation}'")
                    except Exception as e:
                        logging.error(f"‚ùå Translation failed: {e}")
                
                # Actualizar sesi√≥n
                with self.lock:
                    session.total_chunks += 1
                    session.total_duration += duration
                    session.last_activity = datetime.now()
                    
                    # Agregar a transcripci√≥n completa
                    if transcription:
                        if session.full_transcription:
                            session.full_transcription += " " + transcription
                        else:
                            session.full_transcription = transcription
                    
                    if translation:
                        if session.full_translation:
                            session.full_translation += " " + translation
                        else:
                            session.full_translation = translation
                
                processing_time = time.time() - start_time
                
                # Crear respuesta
                response = RealTimeTranscriptionResponse(
                    session_id=session_id,
                    chunk_id=chunk_id,
                    transcription=transcription,
                    translation=translation,
                    detected_language=detected_language,
                    confidence=0.8,  # Valor por defecto
                    is_final=False,
                    processing_time=processing_time,
                    timestamp=datetime.now()
                )
                
                logging.info(f"‚úÖ Processed chunk {chunk_id} in {processing_time:.2f}s")
                return response
                
            finally:
                # Limpiar archivo temporal
                try:
                    if os.path.exists(temp_audio_path):
                        os.remove(temp_audio_path)
                        logging.debug(f"üóëÔ∏è Cleaned temp file: {temp_audio_path}")
                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è Could not clean temp file: {e}")
        
        except Exception as e:
            logging.error(f"‚ùå Error processing chunk {chunk_id}: {e}")
            with self.lock:
                session.status = "error"
                session.error = str(e)
            raise
    
    async def get_session(self, session_id: str) -> Optional[RealTimeSession]:
        """Obtiene informaci√≥n de una sesi√≥n"""
        return self.active_sessions.get(session_id)
    
    async def pause_session(self, session_id: str) -> bool:
        """Pausa una sesi√≥n"""
        if session_id not in self.active_sessions:
            return False
        
        with self.lock:
            self.active_sessions[session_id].status = "paused"
        
        logging.info(f"‚è∏Ô∏è Paused session: {session_id}")
        return True
    
    async def resume_session(self, session_id: str) -> bool:
        """Reanuda una sesi√≥n"""
        if session_id not in self.active_sessions:
            return False
        
        session = self.active_sessions[session_id]
        if session.status != "paused":
            return False
        
        with self.lock:
            session.status = "active"
            session.last_activity = datetime.now()
        
        logging.info(f"‚ñ∂Ô∏è Resumed session: {session_id}")
        return True
    
    async def close_session(self, session_id: str) -> Optional[RealTimeSession]:
        """Cierra una sesi√≥n y devuelve la transcripci√≥n completa"""
        if session_id not in self.active_sessions:
            return None
        
        with self.lock:
            session = self.active_sessions[session_id]
            session.status = "closed"
            session.last_activity = datetime.now()
            
            # Limpiar buffers
            if session_id in self.audio_buffers:
                del self.audio_buffers[session_id]
        
        logging.info(f"üîö Closed session: {session_id} (chunks: {session.total_chunks}, duration: {session.total_duration:.2f}s)")
        return session
    
    def cleanup_expired_sessions(self, max_age_hours: int = 24):
        """Limpia sesiones expiradas"""
        current_time = datetime.now()
        expired_sessions = []
        
        with self.lock:
            for session_id, session in self.active_sessions.items():
                age = (current_time - session.last_activity).total_seconds() / 3600
                if age > max_age_hours:
                    expired_sessions.append(session_id)
            
            for session_id in expired_sessions:
                del self.active_sessions[session_id]
                if session_id in self.audio_buffers:
                    del self.audio_buffers[session_id]
        
        if expired_sessions:
            logging.info(f"üßπ Cleaned {len(expired_sessions)} expired sessions")
